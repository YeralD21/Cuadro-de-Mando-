from pathlib import Path
from typing import Optional, Union

import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
from streamlit.runtime.uploaded_file_manager import UploadedFile

from imblearn.over_sampling import SMOTE
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    confusion_matrix, 
    roc_auc_score, 
    precision_score, 
    recall_score, 
    f1_score,
    classification_report,
    roc_curve
)


DATA_PATH = Path("/Users/usuario/Documents/CUADRO/datamart_ciberseguridad_listo.csv")
LABEL_COL = "is_threat"
RISK_LEVELS = ["Bajo", "Medio", "Alto"]


@st.cache_data(show_spinner=False, hash_funcs={UploadedFile: lambda f: f.file_id})
def load_data(uploaded_file: Optional[Union[Path, UploadedFile]] = None) -> pd.DataFrame:
    if uploaded_file is not None:
        return pd.read_csv(uploaded_file)
    if DATA_PATH.exists():
        return pd.read_csv(DATA_PATH)
    raise FileNotFoundError(
        "No se encontr√≥ el dataset. Sube un archivo CSV desde la barra lateral."
    )


def balance_data(df: pd.DataFrame) -> pd.DataFrame:
    smote = SMOTE(random_state=42)
    features = df.drop(columns=[LABEL_COL])
    target = df[LABEL_COL]
    features_res, target_res = smote.fit_resample(features, target)
    balanced_df = pd.DataFrame(features_res, columns=features.columns)
    balanced_df[LABEL_COL] = target_res
    return balanced_df


def enrich_with_cyber_features(df: pd.DataFrame) -> pd.DataFrame:
    enriched = df.copy()
    duration_seconds = enriched["Flow Duration"].replace(0, np.nan) / 1_000_000
    enriched["Flow Duration (s)"] = duration_seconds.fillna(0)
    enriched["Forward Packets/s (calc)"] = (
        enriched["Total Fwd Packets"] / duration_seconds
    ).replace([np.inf, -np.inf], np.nan).fillna(0)
    enriched["Payload Ratio"] = (
        enriched["Total Length of Fwd Packets"].replace(0, np.nan)
        / enriched["Total Fwd Packets"].replace(0, np.nan)
    ).fillna(0)

    risk_inputs = [
        "Flow Bytes/s",
        "Forward Packets/s (calc)",
        "Flow Duration (s)",
        "Fwd Packet Length Mean",
        "Bwd Packet Length Mean",
    ]
    z_scores = {}
    for col in risk_inputs:
        mean = enriched[col].mean()
        std = enriched[col].std() or 1.0
        z_scores[col] = (enriched[col] - mean) / std

    risk_score = (
        z_scores["Flow Bytes/s"].clip(lower=0)
        + z_scores["Forward Packets/s (calc)"].clip(lower=0)
        + (-z_scores["Flow Duration (s)"]).clip(lower=0)
        + (-z_scores["Fwd Packet Length Mean"]).clip(lower=0)
        + (-z_scores["Bwd Packet Length Mean"]).clip(lower=0)
    )
    enriched["Risk Score (raw)"] = risk_score
    if risk_score.max() > risk_score.min():
        enriched["Risk Score"] = (risk_score - risk_score.min()) / (
            risk_score.max() - risk_score.min()
        )
    else:
        enriched["Risk Score"] = 0.0
    enriched["Risk Level"] = (
        pd.cut(
            enriched["Risk Score"],
            bins=[-np.inf, 0.33, 0.66, np.inf],
            labels=RISK_LEVELS,
        )
        .astype(str)
        .replace("nan", "Bajo")
    )

    enriched["Heur√≠stica: r√°faga r√°pida"] = (
        (enriched["Flow Duration (s)"] <= 0.002)
        & (
            enriched["Total Fwd Packets"]
            >= enriched["Total Fwd Packets"].quantile(0.75)
        )
    )
    enriched["Heur√≠stica: paquetes diminutos"] = (
        (enriched["Fwd Packet Length Mean"] <= enriched["Fwd Packet Length Mean"].quantile(0.25))
        & (
            enriched["Forward Packets/s (calc)"]
            >= enriched["Forward Packets/s (calc)"].quantile(0.75)
        )
    )
    enriched["Heur√≠stica: bytes explosivos"] = (
        enriched["Flow Bytes/s"] >= enriched["Flow Bytes/s"].quantile(0.99)
    )
    return enriched


def render_overview(df: pd.DataFrame, dataset_label: str) -> None:
    st.subheader("Visi√≥n general")
    st.caption(
        f"Resumen ejecutivo del dataset ({dataset_label}). "
        "Estas m√©tricas ayudan a dimensionar el volumen de tr√°fico y el nivel de riesgo."
    )
    total_rows, total_cols = df.shape
    threat_ratio = df[LABEL_COL].mean() * 100
    avg_duration = df["Flow Duration"].mean()
    median_packets = df["Total Fwd Packets"].median()
    mean_bytes = df["Flow Bytes/s"].mean()

    kpi1, kpi2, kpi3, kpi4 = st.columns(4)
    kpi1.metric("Total de flujos", f"{total_rows:,}")
    kpi2.metric("Variables monitorizadas", total_cols)
    kpi3.metric("Amenazas detectadas", f"{int(df[LABEL_COL].eq(1).sum()):,}")
    kpi4.metric("Amenazas (%)", f"{threat_ratio:.2f}")

    gauge = go.Figure(
        go.Indicator(
            mode="gauge+number",
            value=max(threat_ratio, 0.01),
            title={"text": "√çndice de Riesgo (Amenazas %)"},
            gauge={
                "axis": {"range": [0, max(5, threat_ratio * 1.5)]},
                "steps": [
                    {"range": [0, 1], "color": "#3CB371"},
                    {"range": [1, 3], "color": "#FFD700"},
                    {"range": [3, max(5, threat_ratio * 1.5)], "color": "#FF6347"},
                ],
            },
        )
    )
    st.plotly_chart(gauge, use_container_width=True)

    col_a, col_b, col_c = st.columns(3)
    col_a.metric("Duraci√≥n media de flujo (Œºs)", f"{avg_duration:,.0f}")
    col_b.metric("Mediana paquetes Fwd", f"{median_packets:,.0f}")
    col_c.metric("Bytes promedio por segundo", f"{mean_bytes:,.0f}")

    st.write("Vista previa de los primeros registros:")
    st.dataframe(df.head(10), use_container_width=True)


def render_class_distribution(df: pd.DataFrame) -> None:
    st.subheader("Distribuci√≥n de clases")
    st.caption(
        "Compara la cantidad de observaciones etiquetadas como tr√°fico normal frente "
        "a amenazas. √ötil para detectar desbalance de clases antes de entrenar modelos."
    )
    counts = (
        df[LABEL_COL]
            .value_counts()
            .rename_axis(LABEL_COL)
            .reset_index(name="count")
            .replace({LABEL_COL: {0: "Normal", 1: "Amenaza"}})
    )
    fig = px.bar(
        counts,
        x=LABEL_COL,
        y="count",
        labels={LABEL_COL: "Clase", "count": "N√∫mero de registros"},
        text_auto=True,
    )
    fig.update_layout(yaxis_title="N√∫mero de registros", xaxis_title="Clase")
    st.plotly_chart(fig, use_container_width=True)


def render_statistics(df: pd.DataFrame) -> None:
    st.subheader("Estad√≠sticas descriptivas")
    st.caption(
        "Tabla de medidas b√°sicas (m√≠nimo, m√°ximo, cuartiles, media y desviaci√≥n) "
        "para cada variable num√©rica. Permite detectar rangos, escalas y posibles "
        "outliers extremos."
    )
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    st.write("Resumen estad√≠stico para variables num√©ricas:")
    st.dataframe(df[numeric_cols].describe().T, use_container_width=True)

    median_duration = df["Flow Duration"].median()
    p75_duration = df["Flow Duration"].quantile(0.75)
    max_duration = df["Flow Duration"].max()
    median_packets = df["Total Fwd Packets"].median()
    p75_packets = df["Total Fwd Packets"].quantile(0.75)
    max_packets = df["Total Fwd Packets"].max()
    median_fwd_size = df["Fwd Packet Length Mean"].median()
    median_bwd_size = df["Bwd Packet Length Mean"].median()
    threat_share = df[LABEL_COL].mean() * 100

    st.markdown(
        f"""
        **Interpretaci√≥n r√°pida**
        - `Flow Duration` presenta una mediana de {median_duration:,.0f} Œºs (‚âà{median_duration/1e6:.2f} s); el 75‚ÄØ% de los flujos dura menos de {p75_duration:,.0f} Œºs, pero hay outliers que alcanzan {max_duration:,.0f} Œºs (‚âà{max_duration/1e6:.2f} s). Esto evidencia colas muy largas que pueden requerir transformaciones logar√≠tmicas.
        - El tr√°fico suele implicar pocos paquetes (`Total Fwd Packets`: mediana {median_packets:,.0f}, 75‚ÄØ% bajo {p75_packets:,.0f}), aunque existen sesiones masivas de hasta {max_packets:,.0f} paquetes.
        - Los tama√±os medios de paquete son reducidos (medianas {median_fwd_size:,.0f} y {median_bwd_size:,.0f} bytes), lo que concuerda con r√°fagas cortas detectadas en amenazas.
        - Solo {threat_share:.2f}‚ÄØ% de los registros est√° marcado como amenaza, por lo que el dataset es altamente desbalanceado y requerir√° t√©cnicas de balanceo o m√©tricas espec√≠ficas.
        """
    )

    st.write("Selecciona una variable para explorar su distribuci√≥n:")
    st.caption(
        "El histograma muestra la distribuci√≥n de valores segmentada por clase; "
        "el boxplot realza rangos t√≠picos y outliers para cada etiqueta."
    )
    selected_col = st.selectbox("Variable num√©rica", numeric_cols, index=0)
    col1, col2 = st.columns(2)

    hist_fig = px.histogram(
        df,
        x=selected_col,
        color=df[LABEL_COL].map({0: "Normal", 1: "Amenaza"}),
        nbins=40,
        barmode="overlay",
        opacity=0.6,
        labels={selected_col: selected_col, "color": "Clase"},
    )
    hist_fig.update_layout(legend_title="Clase")
    col1.plotly_chart(hist_fig, use_container_width=True)

    box_fig = px.box(
        df,
        x=df[LABEL_COL].map({0: "Normal", 1: "Amenaza"}),
        y=selected_col,
        points="suspectedoutliers",
        labels={"x": "Clase", selected_col: selected_col},
    )
    col2.plotly_chart(box_fig, use_container_width=True)

    st.markdown("#### Diferencias de medias normalizadas")
    class_means = df.groupby(LABEL_COL)[numeric_cols].mean()
    std = df[numeric_cols].std().replace(0, np.nan)
    standardized_diff = (
        (class_means.loc[1] - class_means.loc[0]) / std
    ).dropna().sort_values(key=np.abs, ascending=False)
    diff_fig = px.bar(
        standardized_diff,
        labels={"value": "Diferencia (desviaciones est√°ndar)", "index": "Variable"},
        color=standardized_diff,
        color_continuous_scale="RdBu",
    )
    diff_fig.update_layout(coloraxis_showscale=False)
    st.plotly_chart(diff_fig, use_container_width=True)


def render_correlations(df: pd.DataFrame) -> None:
    st.subheader("Correlaciones")
    st.caption(
        "Mapa de calor con la correlaci√≥n de Pearson entre variables num√©ricas. "
        "El degradado rojo‚Üíblanco‚Üíazul representa magnitudes de 0 (sin relaci√≥n) a 1 "
        "(correlaci√≥n positiva perfecta); cuanto m√°s azul es el recuadro, m√°s tienden "
        "a aumentar ambas variables a la vez. Ayuda a detectar colinealidad o relaciones fuertes."
    )
    numeric_df = df.select_dtypes(include=[np.number]).drop(columns=[LABEL_COL])
    corr = numeric_df.corr()
    fig = px.imshow(
        corr,
        color_continuous_scale="RdBu",
        origin="lower",
        aspect="auto",
        labels=dict(color="Correlaci√≥n"),
    )
    st.plotly_chart(fig, use_container_width=True)

    strongest = (
        corr.abs()
        .where(np.triu(np.ones(corr.shape), k=1).astype(bool))
        .stack()
        .sort_values(ascending=False)
        .head(3)
    )
    explanations = []
    for (feat_a, feat_b), value in strongest.items():
        sign = corr.loc[feat_a, feat_b]
        trend = "positiva" if sign > 0 else "negativa"
        strength = "moderada" if abs(sign) < 0.7 else "fuerte"
        direction = (
            "cuando una variable aumenta, la otra tambi√©n lo hace"
            if sign > 0
            else "cuando una variable aumenta, la otra tiende a disminuir"
        )
        insight = ""
        if {"Total Length of Fwd Packets", "Fwd Packet Length Mean"} == {feat_a, feat_b}:
            insight = (
                " Esto refleja que si un flujo env√≠a muchos bytes hacia adelante, "
                "los paquetes individuales tambi√©n tienden a ser m√°s grandes; en "
                "escenarios de ciberseguridad puede indicar transferencias voluminosas "
                "como exfiltraci√≥n de datos."
            )
        elif {"Flow Duration", "Flow IAT Mean"} == {feat_a, feat_b}:
            insight = (
                " Flujos muy largos suelen traer intervalos medios entre paquetes m√°s "
                "amplios; patrones as√≠ pueden corresponder a conexiones persistentes "
                "como escaneos lentos o beaconing controlado."
        )
        elif {"Total Fwd Packets", "Bwd Packet Length Mean"} == {feat_a, feat_b}:
            insight = (
                " Cuando se env√≠an muchos paquetes hacia adelante, las respuestas "
                "tienden a contener paquetes m√°s grandes; podr√≠a ser s√≠ntoma de "
                "servicios que devuelven grandes bloques tras m√∫ltiples solicitudes, "
                "√∫til para distinguir tr√°fico leg√≠timo masivo de ataques de sondeo."
        )
        explanations.append(
            f"- **{feat_a} ‚Üî {feat_b}**: correlaci√≥n {trend} {strength} de {sign:.2f}, "
            f"{direction}. Puede bastar con usar solo uno de los campos para evitar "
            f"multicolinealidad en modelos lineales.{insight}"
        )
    st.markdown(
        "**Lectura sugerida**\n"
        + "\n".join(explanations)
        + "\n- Valores cercanos a cero indican variables pr√°cticamente independientes, "
        "lo que puede aportar informaci√≥n complementaria a los modelos.\n"
        "- Como regla pr√°ctica: |r| < 0.3 implica relaci√≥n d√©bil, 0.3 ‚â§ |r| < 0.7 "
        "relaci√≥n moderada y |r| ‚â• 0.7 relaci√≥n fuerte."
    )


def render_flow_analysis(df: pd.DataFrame) -> None:
    st.subheader("An√°lisis interactivo de flujos")
    
    # Inicializar session_state para los filtros y selectores
    if "duration_range" not in st.session_state:
        st.session_state.duration_range = (
            float(df["Flow Duration"].quantile(0.05)),
            float(df["Flow Duration"].quantile(0.95)),
        )
    if "packets_range" not in st.session_state:
        st.session_state.packets_range = (
            float(df["Total Fwd Packets"].quantile(0.05)),
            float(df["Total Fwd Packets"].quantile(0.95)),
        )
    
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    if "scatter_x" not in st.session_state:
        st.session_state.scatter_x = "Flow Duration" if "Flow Duration" in numeric_cols else numeric_cols[0]
    if "scatter_y" not in st.session_state:
        st.session_state.scatter_y = "Flow Bytes/s" if "Flow Bytes/s" in numeric_cols else numeric_cols[1] if len(numeric_cols) > 1 else numeric_cols[0]
    
    st.caption("Utiliza los filtros para aislar subconjuntos y comparar indicadores.")
    
    # Calcular rangos donde realmente est√°n las amenazas
    threats_df = df[df[LABEL_COL] == 1]
    normal_df = df[df[LABEL_COL] == 0]
    
    # Rangos basados en distribuci√≥n real de amenazas (usando correlaciones)
    # Hacer rangos MUY amplios para asegurar que siempre incluyan amenazas cuando existan
    # Basado en correlaciones: Flow Duration (negativa), Flow Bytes/s (positiva), Total Fwd Packets (positiva)
    
    # Ejemplo 1: R√°fagas sospechosas - duraci√≥n baja, bytes/s alto (correlaci√≥n negativa con duraci√≥n)
    # Usar rangos muy amplios desde el m√≠nimo hasta percentil alto
    burst_duration_min = float(df["Flow Duration"].min())  # Desde el m√≠nimo absoluto
    burst_duration_max = float(df["Flow Duration"].quantile(0.9))  # Hasta percentil 90
    burst_packets_min = float(df["Total Fwd Packets"].min())
    burst_packets_max = float(df["Total Fwd Packets"].quantile(0.98))  # Muy amplio
    
    # Ejemplo 2: Escaneos masivos - muchos paquetes (correlaci√≥n positiva con Total Fwd Packets)
    # Incluir desde percentil muy bajo hasta casi el m√°ximo
    scan_duration_min = float(df["Flow Duration"].min())  # Desde m√≠nimo
    scan_duration_max = float(df["Flow Duration"].quantile(0.98))  # Hasta percentil 98
    scan_packets_min = float(df["Total Fwd Packets"].quantile(0.05))  # Desde percentil 5
    scan_packets_max = float(df["Total Fwd Packets"].max())  # Hasta el m√°ximo
    
    # Ejemplo 3: Conexiones persistentes - duraci√≥n alta, pocos paquetes
    # Incluir desde percentil medio hasta m√°ximo
    persistent_duration_min = float(df["Flow Duration"].quantile(0.3))  # Desde percentil 30
    persistent_duration_max = float(df["Flow Duration"].max())  # Hasta m√°ximo
    persistent_packets_min = float(df["Total Fwd Packets"].min())
    persistent_packets_max = float(df["Total Fwd Packets"].quantile(0.8))  # Hasta percentil 80
    
    # Calcular cu√°ntas amenazas hay en cada rango de ejemplo
    burst_filtered = df[
        df["Flow Duration"].between(burst_duration_min, burst_duration_max)
        & df["Total Fwd Packets"].between(burst_packets_min, burst_packets_max)
    ]
    burst_threats = int(burst_filtered[LABEL_COL].sum()) if len(burst_filtered) > 0 else 0
    
    scan_filtered = df[
        df["Flow Duration"].between(scan_duration_min, scan_duration_max)
        & df["Total Fwd Packets"].between(scan_packets_min, scan_packets_max)
    ]
    scan_threats = int(scan_filtered[LABEL_COL].sum()) if len(scan_filtered) > 0 else 0
    
    persistent_filtered = df[
        df["Flow Duration"].between(persistent_duration_min, persistent_duration_max)
        & df["Total Fwd Packets"].between(persistent_packets_min, persistent_packets_max)
    ]
    persistent_threats = int(persistent_filtered[LABEL_COL].sum()) if len(persistent_filtered) > 0 else 0
    
    # Ejemplos intuitivos con botones que configuran todo autom√°ticamente
    st.markdown("**üí° Ejemplos r√°pidos (configuraci√≥n autom√°tica):**")
    example_cols = st.columns(3)
    
    with example_cols[0]:
        if st.button("‚ö° Ejemplo 1: R√°fagas sospechosas", use_container_width=True):
            st.session_state.duration_range = (burst_duration_min, burst_duration_max)
            st.session_state.packets_range = (burst_packets_min, burst_packets_max)
            st.session_state.scatter_x = "Flow Duration" if "Flow Duration" in numeric_cols else numeric_cols[0]
            st.session_state.scatter_y = "Flow Bytes/s" if "Flow Bytes/s" in numeric_cols else numeric_cols[1] if len(numeric_cols) > 1 else numeric_cols[0]
            st.rerun()
        st.caption(f"**Eje X:** Flow Duration | **Eje Y:** Flow Bytes/s")
        if burst_threats > 0:
            st.caption(f"‚úÖ Incluye ~{burst_threats:,} amenazas | Busca puntos rojos arriba-izquierda")
        else:
            st.caption("‚ö†Ô∏è Sin amenazas en este rango | Busca puntos rojos arriba-izquierda")
    
    with example_cols[1]:
        if st.button("üì¶ Ejemplo 2: Escaneos masivos", use_container_width=True):
            st.session_state.duration_range = (scan_duration_min, scan_duration_max)
            st.session_state.packets_range = (scan_packets_min, scan_packets_max)
            st.session_state.scatter_x = "Total Fwd Packets" if "Total Fwd Packets" in numeric_cols else numeric_cols[0]
            st.session_state.scatter_y = "Flow Bytes/s" if "Flow Bytes/s" in numeric_cols else numeric_cols[1] if len(numeric_cols) > 1 else numeric_cols[0]
            st.rerun()
        st.caption(f"**Eje X:** Total Fwd Packets | **Eje Y:** Flow Bytes/s")
        if scan_threats > 0:
            st.caption(f"‚úÖ Incluye ~{scan_threats:,} amenazas | Busca puntos rojos arriba-derecha")
        else:
            st.caption("‚ö†Ô∏è Sin amenazas en este rango | Busca puntos rojos arriba-derecha")
    
    with example_cols[2]:
        if st.button("‚è±Ô∏è Ejemplo 3: Conexiones persistentes", use_container_width=True):
            st.session_state.duration_range = (persistent_duration_min, persistent_duration_max)
            st.session_state.packets_range = (persistent_packets_min, persistent_packets_max)
            st.session_state.scatter_x = "Flow Duration" if "Flow Duration" in numeric_cols else numeric_cols[0]
            st.session_state.scatter_y = "Total Fwd Packets" if "Total Fwd Packets" in numeric_cols else numeric_cols[1] if len(numeric_cols) > 1 else numeric_cols[0]
            st.rerun()
        st.caption(f"**Eje X:** Flow Duration | **Eje Y:** Total Fwd Packets")
        if persistent_threats > 0:
            st.caption(f"‚úÖ Incluye ~{persistent_threats:,} amenazas | Busca puntos rojos abajo-derecha")
        else:
            st.caption("‚ö†Ô∏è Sin amenazas en este rango | Busca puntos rojos abajo-derecha")

    col_filter1, col_filter2 = st.columns(2)
    
    # Filtro de duraci√≥n simplificado
    with col_filter1:
        st.markdown("**Duraci√≥n de flujo (Œºs)**")
        if st.button("‚ö° R√°fagas cortas (5k-20k)", use_container_width=True):
            st.session_state.duration_range = (5000.0, 20000.0)
            st.rerun()
        duration_range = st.slider(
            "Rango",
            min_value=float(df["Flow Duration"].min()),
            max_value=float(df["Flow Duration"].max()),
            value=st.session_state.duration_range,
            step=1.0,
            label_visibility="collapsed",
        )
        st.session_state.duration_range = duration_range
    
    # Filtro de paquetes simplificado
    with col_filter2:
        st.markdown("**Total de paquetes forward**")
        if st.button("üì¶ Flujos medios (15-60)", use_container_width=True):
            st.session_state.packets_range = (15.0, 60.0)
            st.rerun()
        packets_range = st.slider(
            "Rango",
            min_value=float(df["Total Fwd Packets"].min()),
            max_value=float(df["Total Fwd Packets"].max()),
            value=st.session_state.packets_range,
            step=1.0,
            label_visibility="collapsed",
        )
        st.session_state.packets_range = packets_range

    filtered = df[
        df["Flow Duration"].between(*duration_range)
        & df["Total Fwd Packets"].between(*packets_range)
    ]

    if filtered.empty:
        st.warning("No hay registros que cumplan con los filtros seleccionados.")
        return
    
    # Verificar si hay amenazas en la vista filtrada
    threats_count = filtered[LABEL_COL].sum()
    normal_count = len(filtered) - threats_count
    
    if threats_count == 0:
        st.warning(f"""
        ‚ö†Ô∏è **No se detectaron amenazas con los filtros actuales** ({normal_count} flujos normales visibles).
        
        **Sugerencia**: Ampl√≠a los rangos de los filtros o usa los botones de ejemplo arriba para ver amenazas.
        Los ejemplos est√°n configurados para mostrar tanto tr√°fico normal (azul) como amenazas (rojo).
        """)

    # Configuraciones r√°pidas para scatter plot
    st.markdown("**Gr√°fico de dispersi√≥n**")
    config_cols = st.columns(3)
    
    with config_cols[0]:
        if st.button("üéØ Duraci√≥n vs Bytes/s", use_container_width=True):
            st.session_state.scatter_x = "Flow Duration" if "Flow Duration" in numeric_cols else numeric_cols[0]
            st.session_state.scatter_y = "Flow Bytes/s" if "Flow Bytes/s" in numeric_cols else numeric_cols[1] if len(numeric_cols) > 1 else numeric_cols[0]
            st.rerun()
    
    with config_cols[1]:
        if st.button("üì¶ Paquetes vs Bytes/s", use_container_width=True):
            st.session_state.scatter_x = "Total Fwd Packets" if "Total Fwd Packets" in numeric_cols else numeric_cols[0]
            st.session_state.scatter_y = "Flow Bytes/s" if "Flow Bytes/s" in numeric_cols else numeric_cols[1] if len(numeric_cols) > 1 else numeric_cols[0]
            st.rerun()
    
    with config_cols[2]:
        if st.button("‚è±Ô∏è Duraci√≥n vs Paquetes", use_container_width=True):
            st.session_state.scatter_x = "Flow Duration" if "Flow Duration" in numeric_cols else numeric_cols[0]
            st.session_state.scatter_y = "Total Fwd Packets" if "Total Fwd Packets" in numeric_cols else numeric_cols[1] if len(numeric_cols) > 1 else numeric_cols[0]
            st.rerun()
    
    # Selectores de ejes simplificados
    col_x, col_y = st.columns(2)
    
    with col_x:
        current_x_idx = numeric_cols.index(st.session_state.scatter_x) if st.session_state.scatter_x in numeric_cols else 0
        scatter_x = st.selectbox(
            "Eje X",
            numeric_cols,
            index=current_x_idx,
            key="scatter_x_selectbox"
        )
        st.session_state.scatter_x = scatter_x
    
    with col_y:
        current_y_idx = numeric_cols.index(st.session_state.scatter_y) if st.session_state.scatter_y in numeric_cols else 1 if len(numeric_cols) > 1 else 0
        scatter_y = st.selectbox(
            "Eje Y",
            numeric_cols,
            index=current_y_idx,
            key="scatter_y_selectbox"
        )
        st.session_state.scatter_y = scatter_y

    # Crear scatter plot con colores personalizados
    color_map = filtered[LABEL_COL].map({0: "Normal", 1: "Amenaza"})
    scatter_fig = px.scatter(
        filtered,
        x=scatter_x,
        y=scatter_y,
        color=color_map,
        opacity=0.7,
        labels={scatter_x: scatter_x, scatter_y: scatter_y, "color": "Clase"},
        hover_data=numeric_cols,
        color_discrete_map={"Normal": "#1976D2", "Amenaza": "#D32F2F"},  # Azul para normal, rojo para amenaza
    )
    st.plotly_chart(scatter_fig, use_container_width=True)
    
    # Gu√≠a de interpretaci√≥n y soluciones pr√°cticas seg√∫n la configuraci√≥n
    duration_min, duration_max = duration_range
    packets_min, packets_max = packets_range
    
    # Determinar tipo de an√°lisis seg√∫n filtros y ejes seleccionados
    is_short_burst = duration_max <= 100000  # Rango m√°s amplio
    is_long_connection = duration_min >= 10000000  # M√°s flexible
    is_many_packets = packets_min >= 10  # M√°s flexible
    
    # Contar amenazas detectadas - c√°lculo din√°mico basado en datos filtrados
    threats_in_view = int(filtered[LABEL_COL].sum())
    normal_in_view = int(len(filtered) - threats_in_view)
    total_in_view = len(filtered)
    threat_percentage = (threats_in_view / total_in_view * 100) if total_in_view > 0 else 0
    
    interpretation = []
    solution = []
    detailed_analysis = []
    
    # Calcular estad√≠sticas comparativas entre amenazas y normales
    if len(filtered) > 0:
        threats_filtered = filtered[filtered[LABEL_COL] == 1]
        normal_filtered = filtered[filtered[LABEL_COL] == 0]
        
        if len(threats_filtered) > 0 and len(normal_filtered) > 0:
            threat_x_mean = threats_filtered[scatter_x].mean()
            normal_x_mean = normal_filtered[scatter_x].mean()
            threat_y_mean = threats_filtered[scatter_y].mean()
            normal_y_mean = normal_filtered[scatter_y].mean()
    
    # Detectar configuraci√≥n seg√∫n ejes y filtros
    if scatter_x == "Flow Duration" and scatter_y == "Flow Bytes/s":
        interpretation.append("üîç **An√°lisis de r√°fagas r√°pidas**: Busca puntos rojos en la esquina superior izquierda (duraci√≥n baja pero bytes/s altos).")
        solution.append("**Soluci√≥n pr√°ctica**: Implementar rate limiting (m√°x 10MB/s por IP), bloquear IPs con transferencias explosivas, y activar alertas autom√°ticas para flujos >5MB/s en <20ms.")
        
        if len(filtered) > 0 and len(threats_filtered) > 0 and len(normal_filtered) > 0:
            detailed_analysis.append(f"""
            **üìä Interpretaci√≥n del an√°lisis:**
            
            Este gr√°fico muestra la relaci√≥n entre **{scatter_x}** (eje X) y **{scatter_y}** (eje Y). 
            
            **Relaci√≥n entre variables**: Existe una correlaci√≥n negativa entre estas variables para las amenazas. 
            Las amenazas tienden a tener duraciones m√°s cortas ({threat_x_mean:,.0f} Œºs promedio) pero tasas de transferencia 
            m√°s altas ({threat_y_mean:,.0f} bytes/s promedio), comparado con tr√°fico normal (duraci√≥n: {normal_x_mean:,.0f} Œºs, 
            bytes/s: {normal_y_mean:,.0f} bytes/s).
            
            **Deducci√≥n**: Se detectaron **{threats_in_view:,} amenazas ({threat_percentage:.1f}%)** cuando se usaron estas variables. 
            Esto demuestra que las amenazas se caracterizan por **transferencias explosivas en per√≠odos muy cortos**, 
            un patr√≥n t√≠pico de ataques de reconocimiento r√°pido, exfiltraci√≥n de datos o escaneos agresivos. 
            Los puntos rojos concentrados en la esquina superior izquierda confirman que las amenazas prefieren 
            maximizar la velocidad de transferencia minimizando el tiempo de exposici√≥n.
            """)
    
    elif scatter_x == "Total Fwd Packets" and scatter_y == "Flow Bytes/s":
        interpretation.append("üîç **An√°lisis de escaneos masivos**: Busca puntos rojos en la esquina superior derecha (muchos paquetes y alta velocidad).")
        solution.append("**Soluci√≥n pr√°ctica**: Configurar firewall con reglas anti-scanning (bloquear >100 paquetes/min), implementar honeypots, y bloquear IPs sospechosas autom√°ticamente.")
        
        if len(filtered) > 0 and len(threats_filtered) > 0 and len(normal_filtered) > 0:
            detailed_analysis.append(f"""
            **üìä Interpretaci√≥n del an√°lisis:**
            
            Este gr√°fico muestra la relaci√≥n entre **{scatter_x}** (eje X) y **{scatter_y}** (eje Y). 
            
            **Relaci√≥n entre variables**: Existe una correlaci√≥n positiva fuerte entre estas variables para las amenazas. 
            Las amenazas tienden a enviar muchos paquetes ({threat_x_mean:,.1f} paquetes promedio) con alta velocidad 
            ({threat_y_mean:,.0f} bytes/s promedio), comparado con tr√°fico normal (paquetes: {normal_x_mean:,.1f}, 
            bytes/s: {normal_y_mean:,.0f} bytes/s).
            
            **Deducci√≥n**: Se detectaron **{threats_in_view:,} amenazas ({threat_percentage:.1f}%)** cuando se usaron estas variables. 
            Esto demuestra que las amenazas se caracterizan por **vol√∫menes masivos de paquetes transmitidos a alta velocidad**, 
            un patr√≥n t√≠pico de escaneos exhaustivos de puertos, ataques DDoS o intentos de exfiltraci√≥n masiva de datos. 
            Los puntos rojos concentrados en la esquina superior derecha confirman que las amenazas buscan maximizar 
            tanto el volumen de tr√°fico como la velocidad, indicando actividad coordinada y agresiva.
            """)
    
    elif scatter_x == "Flow Duration" and scatter_y == "Total Fwd Packets":
        interpretation.append("üîç **An√°lisis de conexiones persistentes**: Busca puntos rojos en la esquina inferior derecha (duraci√≥n alta pero pocos paquetes).")
        solution.append("**Soluci√≥n pr√°ctica**: Implementar timeout de conexiones (m√°x 30 min), monitorear beaconing con an√°lisis de intervalos, y bloquear conexiones sospechosas de C2.")
        
        if len(filtered) > 0 and len(threats_filtered) > 0 and len(normal_filtered) > 0:
            detailed_analysis.append(f"""
            **üìä Interpretaci√≥n del an√°lisis:**
            
            Este gr√°fico muestra la relaci√≥n entre **{scatter_x}** (eje X) y **{scatter_y}** (eje Y). 
            
            **Relaci√≥n entre variables**: Existe una relaci√≥n inversa para las amenazas en este caso. 
            Las amenazas tienden a mantener conexiones muy largas ({threat_x_mean:,.0f} Œºs promedio) pero con pocos paquetes 
            ({threat_y_mean:,.1f} paquetes promedio), comparado con tr√°fico normal (duraci√≥n: {normal_x_mean:,.0f} Œºs, 
            paquetes: {normal_y_mean:,.1f}).
            
            **Deducci√≥n**: Se detectaron **{threats_in_view:,} amenazas ({threat_percentage:.1f}%)** cuando se usaron estas variables. 
            Esto demuestra que las amenazas se caracterizan por **conexiones persistentes con actividad m√≠nima**, 
            un patr√≥n t√≠pico de beaconing (comunicaci√≥n peri√≥dica con servidores de comando y control), conexiones 
            de mantenimiento de acceso o canales de comunicaci√≥n encubiertos. Los puntos rojos concentrados en la 
            esquina inferior derecha confirman que las amenazas prefieren mantener conexiones abiertas durante mucho 
            tiempo pero con tr√°fico m√≠nimo para evitar detecci√≥n, un comportamiento com√∫n en malware avanzado.
            """)
    
    # Interpretaci√≥n gen√©rica si no coincide con ning√∫n caso espec√≠fico pero hay amenazas
    if not detailed_analysis and threats_in_view > 0 and len(filtered) > 0:
        threats_filtered = filtered[filtered[LABEL_COL] == 1]
        normal_filtered = filtered[filtered[LABEL_COL] == 0]
        if len(threats_filtered) > 0 and len(normal_filtered) > 0:
            threat_x_mean = threats_filtered[scatter_x].mean()
            normal_x_mean = normal_filtered[scatter_x].mean()
            threat_y_mean = threats_filtered[scatter_y].mean()
            normal_y_mean = normal_filtered[scatter_y].mean()
            
            detailed_analysis.append(f"""
            **üìä Interpretaci√≥n del an√°lisis:**
            
            Este gr√°fico muestra la relaci√≥n entre **{scatter_x}** (eje X) y **{scatter_y}** (eje Y). 
            
            **Relaci√≥n entre variables**: Comparando las amenazas con el tr√°fico normal, se observa que las amenazas tienen 
            valores promedio de {scatter_x}: {threat_x_mean:,.0f} (vs normal: {normal_x_mean:,.0f}) y {scatter_y}: {threat_y_mean:,.0f} 
            (vs normal: {normal_y_mean:,.0f}).
            
            **Deducci√≥n**: Se detectaron **{threats_in_view:,} amenazas ({threat_percentage:.1f}%)** cuando se usaron estas variables. 
            Analiza la posici√≥n de los puntos rojos en el gr√°fico para identificar patrones espec√≠ficos. Si los puntos rojos 
            est√°n agrupados en zonas diferentes a los azules, indica que las amenazas tienen caracter√≠sticas distintivas que 
            las diferencian del tr√°fico normal, lo cual es √∫til para desarrollar reglas de detecci√≥n.
            """)
    
    # Mostrar informaci√≥n seg√∫n si hay amenazas o no - siempre din√°mico
    if threats_in_view > 0:
        st.success(f"‚úÖ **{threats_in_view:,} amenaza(s) detectada(s)** de {total_in_view:,} flujos en esta vista ({threat_percentage:.1f}%). Busca los puntos rojos en el gr√°fico.")
        if interpretation:
            st.warning(" ".join(interpretation))
            if detailed_analysis:
                with st.expander("üìñ **Interpretaci√≥n detallada del an√°lisis**", expanded=True):
                    st.markdown(" ".join(detailed_analysis))
            st.info(" ".join(solution))
    else:
        if interpretation:
            st.info(" ".join(interpretation))
            if detailed_analysis:
                with st.expander("üìñ **Interpretaci√≥n detallada del an√°lisis**", expanded=True):
                    st.markdown(" ".join(detailed_analysis))
            st.info(" ".join(solution))
        st.caption(f"üí° Compara puntos rojos (amenazas) vs azules (normal). Filtros aplicados: Duraci√≥n {duration_min:,.0f}-{duration_max:,.0f} Œºs, Paquetes {packets_min:.0f}-{packets_max:.0f}. Vista actual: {normal_in_view:,} normales, {threats_in_view:,} amenazas.")

    st.markdown("#### Histogramas comparativos")
    
    # Ejemplos r√°pidos para histogramas
    st.markdown("**üí° Ejemplos r√°pidos para histogramas:**")
    hist_example_cols = st.columns(4)
    
    with hist_example_cols[0]:
        if st.button("üìä Flow Duration", use_container_width=True):
            st.session_state.duration_range = (float(df["Flow Duration"].min()), float(df["Flow Duration"].quantile(0.9)))
            st.session_state.packets_range = (float(df["Total Fwd Packets"].min()), float(df["Total Fwd Packets"].quantile(0.95)))
            st.rerun()
        st.caption("Analiza duraci√≥n")
    
    with hist_example_cols[1]:
        if st.button("üì¶ Total Fwd Packets", use_container_width=True):
            st.session_state.duration_range = (float(df["Flow Duration"].quantile(0.05)), float(df["Flow Duration"].quantile(0.95)))
            st.session_state.packets_range = (float(df["Total Fwd Packets"].quantile(0.1)), float(df["Total Fwd Packets"].max()))
            st.rerun()
        st.caption("Analiza volumen")
    
    with hist_example_cols[2]:
        if st.button("‚ö° Flow Bytes/s", use_container_width=True):
            st.session_state.duration_range = (float(df["Flow Duration"].min()), float(df["Flow Duration"].quantile(0.85)))
            st.session_state.packets_range = (float(df["Total Fwd Packets"].min()), float(df["Total Fwd Packets"].quantile(0.95)))
            st.rerun()
        st.caption("Analiza velocidad")
    
    with hist_example_cols[3]:
        if st.button("üìè Fwd Packet Length Mean", use_container_width=True):
            st.session_state.duration_range = (float(df["Flow Duration"].min()), float(df["Flow Duration"].quantile(0.9)))
            st.session_state.packets_range = (float(df["Total Fwd Packets"].min()), float(df["Total Fwd Packets"].quantile(0.95)))
            st.rerun()
        st.caption("Analiza tama√±o")
    
    hist_col = st.selectbox(
        "Variable",
        numeric_cols,
        index=numeric_cols.index("Flow Duration") if "Flow Duration" in numeric_cols else 0,
    )
    
    hist_comp = px.histogram(
        filtered,
        x=hist_col,
        color=filtered[LABEL_COL].map({0: "Normal", 1: "Amenaza"}),
        barmode="overlay",
        nbins=40,
        opacity=0.6,
        labels={hist_col: hist_col, "color": "Clase"},
        color_discrete_map={"Normal": "#1976D2", "Amenaza": "#D32F2F"},  # Azul para normal, rojo para amenaza
    )
    st.plotly_chart(hist_comp, use_container_width=True)
    
    # Interpretaci√≥n del histograma seg√∫n la variable seleccionada
    if len(filtered) > 0:
        threats_hist = filtered[filtered[LABEL_COL] == 1]
        normal_hist = filtered[filtered[LABEL_COL] == 0]
        
        if len(threats_hist) > 0 and len(normal_hist) > 0:
            threat_mean = threats_hist[hist_col].mean()
            normal_mean = normal_hist[hist_col].mean()
            threat_median = threats_hist[hist_col].median()
            normal_median = normal_hist[hist_col].median()
            threat_q75 = threats_hist[hist_col].quantile(0.75)
            normal_q75 = normal_hist[hist_col].quantile(0.75)
            
            # Determinar qu√© significa la diferencia
            diff_percent = ((threat_mean - normal_mean) / normal_mean * 100) if normal_mean != 0 else 0
            
            # Interpretaciones espec√≠ficas por variable
            hist_interpretation = []
            
            if hist_col == "Flow Duration":
                hist_interpretation.append(f"""
                **üìä Interpretaci√≥n del histograma - {hist_col}:**
                
                Este histograma compara la distribuci√≥n de duraci√≥n de flujos entre tr√°fico normal (azul) y amenazas (rojo).
                
                **An√°lisis estad√≠stico**: Las amenazas tienen una duraci√≥n promedio de {threat_mean:,.0f} Œºs (mediana: {threat_median:,.0f} Œºs), 
                mientras que el tr√°fico normal tiene {normal_mean:,.0f} Œºs (mediana: {normal_median:,.0f} Œºs). 
                Las amenazas en el percentil 75 duran {threat_q75:,.0f} Œºs vs {normal_q75:,.0f} Œºs del tr√°fico normal.
                
                **Deducci√≥n**: {'Las amenazas tienen duraciones significativamente m√°s cortas' if diff_percent < -10 else 'Las amenazas tienen duraciones similares' if abs(diff_percent) < 10 else 'Las amenazas tienen duraciones m√°s largas'} 
                ({abs(diff_percent):.1f}% diferencia). Esto sugiere que las amenazas prefieren conexiones r√°pidas para minimizar 
                el tiempo de exposici√≥n. Si ves barras rojas concentradas en valores bajos de duraci√≥n, confirma el patr√≥n de 
                r√°fagas r√°pidas t√≠pico de escaneos agresivos o exfiltraci√≥n de datos.
                """)
            
            elif hist_col == "Total Fwd Packets":
                hist_interpretation.append(f"""
                **üìä Interpretaci√≥n del histograma - {hist_col}:**
                
                Este histograma compara la distribuci√≥n del volumen de paquetes entre tr√°fico normal (azul) y amenazas (rojo).
                
                **An√°lisis estad√≠stico**: Las amenazas env√≠an un promedio de {threat_mean:,.1f} paquetes (mediana: {threat_median:,.1f}), 
                mientras que el tr√°fico normal env√≠a {normal_mean:,.1f} paquetes (mediana: {normal_median:,.1f}). 
                El percentil 75 de amenazas es {threat_q75:,.1f} paquetes vs {normal_q75:,.1f} del tr√°fico normal.
                
                **Deducci√≥n**: {'Las amenazas env√≠an significativamente m√°s paquetes' if diff_percent > 10 else 'Las amenazas env√≠an vol√∫menes similares' if abs(diff_percent) < 10 else 'Las amenazas env√≠an menos paquetes'} 
                ({diff_percent:+.1f}% diferencia). Si las barras rojas est√°n desplazadas hacia valores altos, indica patrones de 
                escaneo exhaustivo o transferencias masivas. Si est√°n en valores bajos, pueden ser sondeos iniciales o conexiones 
                de beaconing con pocos paquetes.
                """)
            
            elif hist_col == "Flow Bytes/s":
                hist_interpretation.append(f"""
                **üìä Interpretaci√≥n del histograma - {hist_col}:**
                
                Este histograma compara la distribuci√≥n de velocidad de transferencia entre tr√°fico normal (azul) y amenazas (rojo).
                
                **An√°lisis estad√≠stico**: Las amenazas tienen una velocidad promedio de {threat_mean:,.0f} bytes/s (mediana: {threat_median:,.0f} bytes/s), 
                mientras que el tr√°fico normal tiene {normal_mean:,.0f} bytes/s (mediana: {normal_median:,.0f} bytes/s). 
                El percentil 75 de amenazas es {threat_q75:,.0f} bytes/s vs {normal_q75:,.0f} bytes/s del tr√°fico normal.
                
                **Deducci√≥n**: {'Las amenazas tienen velocidades significativamente m√°s altas' if diff_percent > 10 else 'Las amenazas tienen velocidades similares' if abs(diff_percent) < 10 else 'Las amenazas tienen velocidades m√°s bajas'} 
                ({diff_percent:+.1f}% diferencia). Si las barras rojas est√°n concentradas en valores altos, confirma transferencias 
                explosivas t√≠picas de exfiltraci√≥n de datos o ataques de reconocimiento r√°pido. Valores extremadamente altos pueden 
                indicar intentos de saturaci√≥n de ancho de banda o DDoS.
                """)
            
            elif hist_col == "Fwd Packet Length Mean":
                hist_interpretation.append(f"""
                **üìä Interpretaci√≥n del histograma - {hist_col}:**
                
                Este histograma compara la distribuci√≥n del tama√±o promedio de paquetes forward entre tr√°fico normal (azul) y amenazas (rojo).
                
                **An√°lisis estad√≠stico**: Las amenazas tienen un tama√±o promedio de paquete de {threat_mean:,.1f} bytes (mediana: {threat_median:,.1f} bytes), 
                mientras que el tr√°fico normal tiene {normal_mean:,.1f} bytes (mediana: {normal_median:,.1f} bytes). 
                El percentil 75 de amenazas es {threat_q75:,.1f} bytes vs {normal_q75:,.1f} bytes del tr√°fico normal.
                
                **Deducci√≥n**: {'Las amenazas usan paquetes significativamente m√°s grandes' if diff_percent > 10 else 'Las amenazas usan tama√±os similares' if abs(diff_percent) < 10 else 'Las amenazas usan paquetes m√°s peque√±os'} 
                ({diff_percent:+.1f}% diferencia). Paquetes muy peque√±os pueden indicar escaneos sigilosos o reconocimiento, mientras que 
                paquetes grandes pueden sugerir transferencias de datos o payloads maliciosos. La distribuci√≥n te ayuda a identificar 
                qu√© rangos de tama√±o son m√°s sospechosos.
                """)
            
            else:
                # Interpretaci√≥n gen√©rica para otras variables
                hist_interpretation.append(f"""
                **üìä Interpretaci√≥n del histograma - {hist_col}:**
                
                Este histograma compara la distribuci√≥n de **{hist_col}** entre tr√°fico normal (azul) y amenazas (rojo).
                
                **An√°lisis estad√≠stico**: Las amenazas tienen un valor promedio de {threat_mean:,.1f} (mediana: {threat_median:,.1f}), 
                mientras que el tr√°fico normal tiene {normal_mean:,.1f} (mediana: {normal_median:,.1f}). 
                El percentil 75 de amenazas es {threat_q75:,.1f} vs {normal_q75:,.1f} del tr√°fico normal.
                
                **Deducci√≥n**: {'Las amenazas tienen valores significativamente m√°s altos' if diff_percent > 10 else 'Las amenazas tienen valores similares' if abs(diff_percent) < 10 else 'Las amenazas tienen valores m√°s bajos'} 
                ({diff_percent:+.1f}% diferencia). Analiza d√≥nde se concentran las barras rojas en comparaci√≥n con las azules. 
                Si est√°n en rangos diferentes, indica que esta variable es √∫til para distinguir amenazas del tr√°fico normal.
                """)
            
            if hist_interpretation:
                with st.expander("üìñ **Interpretaci√≥n del histograma**", expanded=True):
                    st.markdown(" ".join(hist_interpretation))

    st.markdown("#### Tabla filtrada")
    st.dataframe(filtered.head(100), use_container_width=True)


def render_balance_section(original_df: pd.DataFrame, balanced_df: pd.DataFrame) -> None:
    st.subheader("Comparativa dataset original vs balanceado")
    st.caption(
        "Eval√∫a c√≥mo cambia la distribuci√≥n de m√©tricas al aplicar SMOTE. "
        "Los datos sint√©ticos permiten entrenar modelos menos sesgados."
    )

    col1, col2 = st.columns(2)
    for col, data, label in (
        (col1, original_df, "Original"),
        (col2, balanced_df, "Balanceado"),
    ):
        col.metric(f"Filas ({label})", f"{len(data):,}")
        col.metric(
            f"Amenazas ({label})",
            f"{data[LABEL_COL].sum():,}",
            f"{data[LABEL_COL].mean()*100:.2f} %",
        )

    dist_fig = px.histogram(
        original_df,
        x="Flow Duration",
        color=original_df[LABEL_COL].map({0: "Normal", 1: "Amenaza"}),
        nbins=40,
        opacity=0.5,
        marginal="box",
        labels={"color": "Clase"},
    )
    dist_fig.update_layout(title="Distribuci√≥n de duraci√≥n de flujo (dataset original)")
    st.plotly_chart(dist_fig, use_container_width=True)

    dist_balanced = px.histogram(
        balanced_df,
        x="Flow Duration",
        color=balanced_df[LABEL_COL].map({0: "Normal", 1: "Amenaza"}),
        nbins=40,
        opacity=0.5,
        marginal="box",
        labels={"color": "Clase"},
    )
    dist_balanced.update_layout(
        title="Distribuci√≥n de duraci√≥n de flujo (dataset balanceado)"
    )
    st.plotly_chart(dist_balanced, use_container_width=True)


def render_model_results(df: pd.DataFrame, auc_score: float) -> None:
    """
    Muestra los resultados del modelo de Regresi√≥n Log√≠stica calibrado.
    """
    st.subheader("Resultados del Modelo Predictivo (Regresi√≥n Log√≠stica)")
    st.caption(
        "Esta pesta√±a muestra los resultados del modelo de ML (entrenado en Colab) "
        "aplicando el **umbral √≥ptimo de 1.5% (0.015)**. "
        "Estos son los resultados finales que se usar√≠an en producci√≥n."
    )

    # Verificar que las columnas necesarias existan
    if 'ML Model Score' not in df.columns or 'ML Model Alert' not in df.columns:
        st.error("Las columnas 'ML Model Score' y 'ML Model Alert' no est√°n disponibles. "
                 "Aseg√∫rate de usar el 'Dataset original' para ver los resultados del modelo.")
        return

    # --- M√©trica de Calidad del Modelo (AUC) ---
    st.metric(
        label="Calidad del Modelo (AUC Score)",
        value=f"{auc_score:.4f}",
        help="√Årea Bajo la Curva ROC (calculada en el set de prueba). "
             "Un valor de 1.0 es perfecto, 0.5 es aleatorio. "
             "Este alto valor demuestra que el modelo es s√≥lido."
    )
    st.divider()

    # --- KPIs Clave del Modelo Calibrado ---
    st.markdown("#### KPIs de Rendimiento del Modelo (Umbral 1.5%)")
    
    # Calcular m√©tricas usando confusion_matrix de sklearn
    cm = confusion_matrix(df[LABEL_COL], df["ML Model Alert"])
    tn, fp, fn, tp = cm.ravel()
    
    total_alerts = fp + tp
    
    kpi1, kpi2, kpi3, kpi4 = st.columns(4)
    kpi1.metric("Ataques Reales Detectados (TP)", f"{tp:,}")
    kpi2.metric("Falsas Alarmas (FP)", f"{fp:,}")
    kpi3.metric("Ataques Omitidos (FN)", f"{fn:,}")
    kpi4.metric("Total Alertas Generadas", f"{total_alerts:,}")

    if fn == 0:
        st.success(
            "¬°√âXITO! Con el umbral de 1.5%, el modelo detect√≥ el 100% de las "
            "amenazas reales (0 Ataques Omitidos), cumpliendo el objetivo principal."
        )
    else:
        st.error(
            f"FALLO: El modelo omiti√≥ {fn} ataques. Revisar calibraci√≥n."
        )

    # --- Matriz de Confusi√≥n Visual ---
    st.markdown("#### Matriz de Confusi√≥n (Umbral 1.5%)")
    st.caption(
        "Muestra el balance visual entre la Verdad Real (`is_threat`) y la "
        "Predicci√≥n del Modelo (`ML Model Alert`)."
    )
    # Crear un DataFrame para el heatmap de Plotly
    cm_df = pd.DataFrame(
        cm,
        index=["Real: Normal (0)", "Real: Amenaza (1)"],
        columns=["Predicho: Normal (0)", "Predicho: Alerta (1)"]
    )
    fig_cm = px.imshow(
        cm_df, 
        text_auto=True, 
        aspect="auto", 
        color_continuous_scale='Blues',
        labels=dict(x="Predicci√≥n del Modelo", y="Verdad Real", color="Cantidad")
    )
    st.plotly_chart(fig_cm, use_container_width=True)

    # --- Tabla de Priorizaci√≥n de Alertas ---
    st.markdown("#### Tabla de Priorizaci√≥n de Alertas (Accionable)")
    st.caption(
        "Esta es la 'Lista de Tareas' para un analista. Muestra solo las "
        f"{total_alerts} alertas generadas, ordenadas por el 'ML Model Score' "
        "(el m√°s riesgoso primero) para una investigaci√≥n eficiente."
    )
    
    priority_table = df[df["ML Model Alert"] == 1].sort_values(
        "ML Model Score", ascending=False
    )
    
    display_cols = [
        "ML Model Score",
        "is_threat",  # Para verificar si fue un acierto
        "Flow Duration",
        "Flow Bytes/s",
        "Total Fwd Packets",
        "Fwd Packet Length Mean",
    ]
    
    # A√±adir Risk Score si existe
    if 'Risk Score' in priority_table.columns:
        display_cols.insert(2, "Risk Score")
    
    available_cols = [col for col in display_cols if col in priority_table.columns]
    st.dataframe(
        priority_table[available_cols].head(20),  # Mostrar solo las 20 m√°s cr√≠ticas
        use_container_width=True
    )
    
    # Interpretaci√≥n autom√°tica
    if not priority_table.empty:
        st.markdown("#### üìä Interpretaci√≥n de los Resultados")
        
        top_20 = priority_table.head(20)
        real_threats_top20 = top_20[LABEL_COL].sum()
        false_positives_top20 = len(top_20) - real_threats_top20
        avg_ml_score = top_20['ML Model Score'].mean()
        
        interpretation = f"""
        **Resumen Ejecutivo:**
        
        De los **20 flujos m√°s riesgosos** identificados por el modelo ML:
        - ‚úÖ **{real_threats_top20} son amenazas reales** (Verdaderos Positivos)
        - ‚ö†Ô∏è **{false_positives_top20} son falsas alarmas** (Falsos Positivos)
        - üìà **Score promedio del modelo:** {avg_ml_score:.4f} (umbral: 0.0150)
        - üéØ **Tasa de precisi√≥n en Top 20:** {(real_threats_top20/len(top_20)*100):.1f}%
        
        **Implicaciones para la Seguridad:**
        - El modelo ML est√° siendo **conservador** al generar alertas incluso para flujos con caracter√≠sticas at√≠picas pero no necesariamente maliciosas.
        - La presencia de falsos positivos en los Top 20 sugiere que el umbral podr√≠a ajustarse, pero esto debe balancearse con la necesidad de detectar todas las amenazas reales.
        """
        
        st.markdown(interpretation)


@st.cache_resource(show_spinner="Entrenando Modelo de ML...")
def train_and_get_model_predictions(df: pd.DataFrame) -> tuple:
    """
    Entrena un modelo de Regresi√≥n Log√≠stica y devuelve las predicciones 
    para todo el dataframe junto con el AUC score del set de prueba.
    """
    # 1. Definir las 7 caracter√≠sticas originales del Data Mart
    features = [
        "Flow Duration", "Total Fwd Packets", "Total Length of Fwd Packets",
        "Flow Bytes/s", "Flow IAT Mean", "Fwd Packet Length Mean", 
        "Bwd Packet Length Mean"
    ]
    target = "is_threat"

    X = df[features]
    y = df[target]

    # 2. Dividir los datos para un entrenamiento robusto
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    # 3. Escalar los datos
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # 4. Entrenar el modelo
    model = LogisticRegression(max_iter=1000, random_state=42)
    model.fit(X_train_scaled, y_train)

    # 5. Calcular AUC score en el set de prueba
    y_test_proba = model.predict_proba(X_test_scaled)[:, 1]
    auc_score = roc_auc_score(y_test, y_test_proba)

    # 6. Generar predicciones para TODO el dataset
    X_full_scaled = scaler.transform(X[features])
    ml_scores = model.predict_proba(X_full_scaled)[:, 1]

    # 7. Definir el umbral √≥ptimo que encontramos (1.5%)
    UMBRAL_OPTIMO = 0.015
    
    results_df = pd.DataFrame(index=df.index)
    results_df["ML Model Score"] = ml_scores
    results_df["ML Model Alert"] = (ml_scores >= UMBRAL_OPTIMO).astype(int)
    
    return results_df, auc_score


def render_calibration_tuning(df: pd.DataFrame) -> None:
    """
    Muestra un slider interactivo para que el usuario explore c√≥mo
    cambia el rendimiento del modelo al ajustar el umbral de decisi√≥n.
    """
    st.subheader("Visualizador Interactivo de Umbral (Calibraci√≥n)")
    st.caption(
        "Esta es la demostraci√≥n de la **Fase 5: Evaluaci√≥n y Calibraci√≥n**. "
        "Usa el slider para ver c√≥mo un peque√±o cambio en el umbral de decisi√≥n "
        "impacta dr√°sticamente el costo (Falsas Alarmas) y el riesgo (Ataques Omitidos)."
    )

    # Verificar que las columnas necesarias existan
    if 'ML Model Score' not in df.columns:
        st.error("La columna 'ML Model Score' no est√° disponible. "
                 "Aseg√∫rate de usar el 'Dataset original' para ver la calibraci√≥n.")
        return

    # Crear una copia local para evitar modificar el dataframe original
    df_local = df.copy()

    # 1. Crear el Slider
    umbral_dinamico_pct = st.slider(
        "Selecciona un Umbral de Decisi√≥n (%)",
        min_value=0.5,
        max_value=5.0,
        value=1.5,  # Nuestro √≥ptimo
        step=0.1,
        format="%.1f%%"
    )
    umbral_dinamico = umbral_dinamico_pct / 100.0  # Convertir a decimal (ej. 0.015)

    # 2. Recalcular predicciones y m√©tricas din√°micamente
    df_local['alerta_dinamica'] = (df_local['ML Model Score'] >= umbral_dinamico).astype(int)
    
    cm_dinamico = confusion_matrix(df_local[LABEL_COL], df_local['alerta_dinamica'])
    
    # Manejar el caso raro de que no haya 4 valores (ej. en umbrales muy altos)
    if len(cm_dinamico.ravel()) == 4:
        tn, fp, fn, tp = cm_dinamico.ravel()
    else:
        # Asumir que solo hay TN (todo predicho como 0)
        tn = cm_dinamico.ravel()[0]
        fp, fn, tp = 0, df_local[LABEL_COL].sum(), 0

    # 3. Calcular m√©tricas adicionales para mejor interpretaci√≥n
    total_threats = df_local[LABEL_COL].sum()
    fn_percentage = (fn / total_threats * 100) if total_threats > 0 else 0
    detection_rate = (tp / total_threats * 100) if total_threats > 0 else 0
    
    # Calcular m√©tricas del umbral √≥ptimo (1.5%) para comparaci√≥n
    umbral_optimo = 0.015
    df_local['alerta_optima'] = (df_local['ML Model Score'] >= umbral_optimo).astype(int)
    cm_optimo = confusion_matrix(df_local[LABEL_COL], df_local['alerta_optima'])
    if len(cm_optimo.ravel()) == 4:
        _, fp_optimo, fn_optimo, tp_optimo = cm_optimo.ravel()
    else:
        fp_optimo, fn_optimo, tp_optimo = 0, total_threats, 0

    # 4. Mostrar KPIs din√°micos
    st.markdown("#### M√©tricas de Impacto (en tiempo real)")
    st.caption(
        "Observa c√≥mo el umbral afecta la detecci√≥n de amenazas. El umbral √≥ptimo de 1.5% "
        "fue calibrado para minimizar el riesgo de ataques omitidos mientras se controla el volumen de falsas alarmas."
    )
    
    kpi1, kpi2, kpi3, kpi4 = st.columns(4)
    kpi1.metric("Ataques Detectados (TP)", f"{tp:,}", f"{detection_rate:.2f}% del total")
    kpi2.metric("Ataques Omitidos (FN)", f"{fn:,}", f"{fn_percentage:.2f}% del total")
    kpi3.metric("Falsas Alarmas (FP)", f"{fp:,}")
    
    # Mostrar comparaci√≥n con umbral √≥ptimo
    if abs(umbral_dinamico_pct - 1.5) < 0.1:  # Dentro de ¬±0.1% del √≥ptimo
        kpi4.metric("Estado", "Umbral √ìptimo", "1.5%")
    else:
        diff_fp = fp - fp_optimo
        kpi4.metric("vs. √ìptimo (1.5%)", f"FP: {diff_fp:+,}", 
                   f"FN: {fn - fn_optimo:+d}")

    # 5. Mensajes contextuales mejorados
    # Tolerancia: considerar √≥ptimo si est√° cerca de 1.5% y el riesgo es bajo
    umbral_cerca_optimo = abs(umbral_dinamico_pct - 1.5) < 0.2
    riesgo_bajo = fn_percentage < 2.0  # Menos del 2% de amenazas omitidas
    
    if fn == 0:
        if umbral_cerca_optimo:
            st.success(
                f"**‚úÖ Umbral √ìptimo ({umbral_dinamico_pct:.1f}%):** "
                f"Detecci√≥n perfecta (100% de amenazas detectadas) con {fp:,} falsas alarmas. "
                f"Este es el punto de equilibrio ideal entre seguridad y eficiencia operativa."
            )
        else:
            st.info(
                f"**Detecci√≥n Completa:** Con este umbral se detectan todas las amenazas ({tp:,} de {total_threats:,}), "
                f"pero genera {fp:,} falsas alarmas. El umbral √≥ptimo de 1.5% ofrece mejor balance."
            )
    elif riesgo_bajo and umbral_cerca_optimo:
        st.success(
            f"**‚úÖ Umbral Cercano al √ìptimo ({umbral_dinamico_pct:.1f}%):** "
            f"Riesgo muy bajo ({fn_percentage:.2f}% de amenazas omitidas, {fn} de {total_threats}). "
            f"Se detectan {detection_rate:.2f}% de las amenazas con {fp:,} falsas alarmas. "
            f"Este umbral ofrece un excelente balance entre seguridad y eficiencia."
        )
    elif riesgo_bajo:
        st.info(
            f"**Riesgo Bajo:** Con este umbral se omiten {fn} amenazas ({fn_percentage:.2f}% del total), "
            f"lo cual representa un riesgo aceptable. Se detectan {detection_rate:.2f}% de las amenazas "
            f"con {fp:,} falsas alarmas. Considera ajustar hacia 1.5% para optimizar el balance."
        )
    elif fn_percentage < 5.0:  # Menos del 5% de riesgo
        st.warning(
            f"**‚ö†Ô∏è Riesgo Moderado:** El modelo est√° omitiendo {fn} amenazas ({fn_percentage:.2f}% del total). "
            f"Se detectan {detection_rate:.2f}% de las amenazas. "
            f"Se recomienda reducir el umbral hacia 1.5% para mejorar la detecci√≥n."
        )
    else:
        st.error(
            f"**üö® Riesgo Alto:** Con este umbral se est√°n omitiendo {fn} amenazas ({fn_percentage:.2f}% del total), "
            f"lo cual es significativo. Solo se detectan {detection_rate:.2f}% de las amenazas. "
            f"Se recomienda reducir el umbral a 1.5% o menos para mejorar la seguridad."
        )


def render_cybersecurity_focus(df: pd.DataFrame) -> None:
    st.subheader("Perspectiva de ciberseguridad")
    st.caption(
        "Visualiza heur√≠sticas defensivas (r√°fagas, paquetes diminutos, bytes explosivos) y el puntaje de riesgo generado a partir de los indicadores de red."
    )

    total_flows = len(df)
    high_risk = df[df["Risk Level"] == "Alto"]
    medium_risk = df[df["Risk Level"] == "Medio"]

    col1, col2, col3 = st.columns(3)
    high_risk_count = len(high_risk)
    medium_risk_count = len(medium_risk)
    high_risk_pct = high_risk_count/total_flows*100
    medium_risk_pct = medium_risk_count/total_flows*100
    threat_match = df[(df['Risk Level'] == 'Alto') & (df[LABEL_COL] == 1)].shape[0]
    
    col1.metric("Flujos de alto riesgo", f"{high_risk_count:,}", f"{high_risk_pct:.2f}%")
    col2.metric("Flujos medio riesgo", f"{medium_risk_count:,}", f"{medium_risk_pct:.2f}%")
    col3.metric(
        "Coincidencia con etiqueta 'Amenaza'",
        f"{threat_match:,}",
        help="Cantidad de flujos que el dataset etiqueta como amenaza y adem√°s nuestra heur√≠stica marca como alto riesgo.",
    )
    
    # Interpretaci√≥n de las m√©tricas
    st.info(f"""
    **üìä Interpretaci√≥n de m√©tricas**: De {total_flows:,} flujos analizados, {high_risk_count:,} ({high_risk_pct:.2f}%) 
    son de alto riesgo y {medium_risk_count:,} ({medium_risk_pct:.2f}%) de riesgo medio. 
    {'‚úÖ La heur√≠stica detect√≥ correctamente ' + str(threat_match) + ' amenazas reales marcadas como alto riesgo.' if threat_match > 0 else '‚ö†Ô∏è Revisar calibraci√≥n: no hay coincidencias entre alto riesgo y amenazas etiquetadas.'}
    """)

    st.markdown("#### Distribuci√≥n de puntajes de riesgo")
    risk_dist = px.histogram(
        df,
        x="Risk Score",
        color="Risk Level",
        nbins=40,
        color_discrete_map={"Bajo": "#4CAF50", "Medio": "#FFC107", "Alto": "#F44336"},
        labels={"Risk Score": "Puntaje de riesgo normalizado", "Risk Level": "Nivel"},
    )
    st.plotly_chart(risk_dist, use_container_width=True)
    
    # Interpretaci√≥n del histograma de riesgo
    low_risk_count = len(df[df["Risk Level"] == "Bajo"])
    low_risk_pct = low_risk_count/total_flows*100
    avg_risk_score = df["Risk Score"].mean()
    
    st.caption(f"""
    **üìä Interpretaci√≥n**: El histograma muestra que la mayor√≠a de flujos ({low_risk_count:,}, {low_risk_pct:.1f}%) 
    tienen riesgo bajo (verde), concentrados en scores bajos. Los flujos de alto riesgo (rojo) son minoritarios 
    y se concentran en scores altos (>0.66). El score promedio es {avg_risk_score:.3f}. 
    Una distribuci√≥n sesgada hacia valores bajos es esperada en un entorno seguro, pero los picos en riesgo alto 
    requieren investigaci√≥n inmediata.
    """)

    heuristics = {
        "Heur√≠stica: r√°faga r√°pida": "Detecta r√°fagas extremadamente cortas con muchos paquetes, patrones t√≠picos de escaneo agresivo.",
        "Heur√≠stica: paquetes diminutos": "Se√±ala flujos con paquetes muy peque√±os enviados r√°pidamente, com√∫n en escaneo o reconocimiento sigiloso.",
        "Heur√≠stica: bytes explosivos": "Identifica flujos con tasa de bytes por segundo inusualmente alta, potencial exfiltraci√≥n o transferencia maliciosa.",
    }
    heuristic_data = []
    for col, desc in heuristics.items():
        matches = df[df[col]]
        heuristic_data.append(
            {
                "Heur√≠stica": col.replace("Heur√≠stica: ", ""),
                "Coincidencias": len(matches),
                "% del total": f"{len(matches)/total_flows*100:.2f}%",
                "Amenazas etiquetadas": matches[LABEL_COL].sum(),
                "Descripci√≥n": desc,
            }
        )
    st.markdown("#### Reglas heur√≠sticas activadas")
    st.dataframe(pd.DataFrame(heuristic_data), use_container_width=True)
    
    # Interpretaci√≥n de la tabla de heur√≠sticas
    total_heuristic_matches = sum([len(df[df[col]]) for col in heuristics.keys()])
    total_threats_detected = sum([df[df[col]][LABEL_COL].sum() for col in heuristics.keys()])
    
    st.caption(f"""
    **üìä Interpretaci√≥n**: Las 3 reglas heur√≠sticas detectaron {total_heuristic_matches:,} flujos sospechosos en total. 
    De estos, {total_threats_detected:,} coinciden con amenazas etiquetadas. Las heur√≠sticas funcionan como filtros 
    complementarios: una r√°faga r√°pida puede no ser amenaza, pero si adem√°s tiene paquetes diminutos o bytes explosivos, 
    aumenta la probabilidad de ser maliciosa. Usa esta tabla para identificar qu√© patrones son m√°s efectivos.
    """)

    st.markdown("#### Flujos m√°s cr√≠ticos seg√∫n puntaje de riesgo")
    top_risk = df.sort_values("Risk Score", ascending=False).head(20)
    top_risk_threats = top_risk[LABEL_COL].sum()
    avg_top_risk_score = top_risk["Risk Score"].mean()
    
    st.dataframe(
        top_risk[
            [
                "Risk Score",
                "Risk Level",
                "Flow Duration",
                "Total Fwd Packets",
                "Flow Bytes/s",
                "Fwd Packet Length Mean",
                "Bwd Packet Length Mean",
                LABEL_COL,
            ]
        ],
        use_container_width=True,
    )
    
    # Interpretaci√≥n de la tabla de flujos cr√≠ticos
    st.caption(f"""
    **üìä Interpretaci√≥n**: Esta tabla muestra los 20 flujos con mayor Risk Score (promedio: {avg_top_risk_score:.3f}). 
    {'‚úÖ ' + str(top_risk_threats) + ' de estos flujos son amenazas reales confirmadas' if top_risk_threats > 0 else '‚ö†Ô∏è Ninguno de los flujos de mayor riesgo coincide con amenazas etiquetadas; revisar calibraci√≥n de Risk Score.'} 
    Los flujos est√°n ordenados por riesgo descendente para priorizar investigaciones. Analiza las m√©tricas 
    (duraci√≥n, paquetes, bytes/s) para identificar patrones comunes entre los flujos m√°s riesgosos.
    """)


def render_comparison(df: pd.DataFrame) -> None:
    """
    Compara el enfoque heur√≠stico con el modelo de ML.
    """
    st.subheader("Comparativa: Enfoque Heur√≠stico vs. Modelo ML")
    st.caption(
        "Esta secci√≥n permite comparar directamente ambos enfoques de detecci√≥n de amenazas "
        "para evaluar sus fortalezas y debilidades complementarias."
    )
    
    # Verificar que las columnas necesarias existan
    if 'ML Model Score' not in df.columns or 'ML Model Alert' not in df.columns:
        st.error("Las columnas 'ML Model Score' y 'ML Model Alert' no est√°n disponibles. "
                 "Aseg√∫rate de usar el 'Dataset original' para ver la comparativa.")
        return
    
    if 'Risk Score' not in df.columns or 'Risk Level' not in df.columns:
        st.error("Las columnas 'Risk Score' y 'Risk Level' no est√°n disponibles.")
        return
    
    # --- Comparativa de Rendimiento Final ---
    st.markdown("#### Comparativa de Rendimiento Final")
    st.caption(
        "Comparaci√≥n directa del rendimiento entre el modelo Heur√≠stico "
        "(basado en reglas 'Risk Level') y el modelo de ML (calibrado a 1.5%)."
    )

    col1, col2 = st.columns(2)

    # --- Columna 1: Modelo de ML (El Ganador) ---
    with col1:
        st.markdown("##### Modelo ML (Calibrado a 1.5%)")
        cm_ml = confusion_matrix(df[LABEL_COL], df["ML Model Alert"])
        if len(cm_ml.ravel()) == 4:
            tn_ml, fp_ml, fn_ml, tp_ml = cm_ml.ravel()
        else:
            tn_ml, fp_ml, fn_ml, tp_ml = df[df[LABEL_COL]==0].shape[0], 0, df[df[LABEL_COL]==1].shape[0], 0
            
        st.metric("Ataques Detectados (TP)", f"{tp_ml:,}")
        st.metric("Ataques Omitidos (FN)", f"{fn_ml:,}")
        st.metric("Falsas Alarmas (FP)", f"{fp_ml:,}")

    # --- Columna 2: Modelo Heur√≠stico ---
    with col2:
        st.markdown("##### Modelo Heur√≠stico ('Risk Level')")
        # Asumir que 'Alto' es la alerta heur√≠stica
        heuristica_alerta = (df['Risk Level'] == 'Alto').astype(int)
        cm_heu = confusion_matrix(df[LABEL_COL], heuristica_alerta)
        
        if len(cm_heu.ravel()) == 4:
            tn_heu, fp_heu, fn_heu, tp_heu = cm_heu.ravel()
        else:
            tn_heu, fp_heu, fn_heu, tp_heu = df[df[LABEL_COL]==0].shape[0], 0, df[df[LABEL_COL]==1].shape[0], 0

        st.metric("Ataques Detectados (TP)", f"{tp_heu:,}")
        st.metric("Ataques Omitidos (FN)", f"{fn_heu:,}")
        st.metric("Falsas Alarmas (FP)", f"{fp_heu:,}")

    # --- Veredicto ---
    if fn_ml == 0 and fn_heu > fn_ml:
        st.success(
            f"**Veredicto:** El modelo de ML es superior. "
            f"El modelo Heur√≠stico omiti√≥ {fn_heu} ataques, mientras que "
            "el modelo de ML (calibrado a 1.5%) no omiti√≥ ninguno."
        )
    
    st.divider()
    
    # M√©tricas comparativas
    st.markdown("#### M√©tricas Comparativas")
    
    # Alertas heur√≠sticas (usando Risk Level Alto)
    heuristic_alerts = df[df['Risk Level'] == 'Alto']
    ml_alerts = df[df['ML Model Alert'] == 1]
    
    # Intersecci√≥n y diferencias
    heuristic_only = heuristic_alerts[~heuristic_alerts.index.isin(ml_alerts.index)]
    ml_only = ml_alerts[~ml_alerts.index.isin(heuristic_alerts.index)]
    both_methods = heuristic_alerts[heuristic_alerts.index.isin(ml_alerts.index)]
    
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Alertas Heur√≠sticas (Alto Riesgo)", f"{len(heuristic_alerts):,}")
    col2.metric("Alertas ML (Umbral 1.5%)", f"{len(ml_alerts):,}")
    col3.metric("Detectadas por Ambos", f"{len(both_methods):,}")
    col4.metric("Solo Heur√≠stica", f"{len(heuristic_only):,}")
    
    col5, col6 = st.columns(2)
    col5.metric("Solo ML", f"{len(ml_only):,}")
    
    # Precisi√≥n comparativa
    heuristic_tp = heuristic_alerts[LABEL_COL].sum()
    ml_tp = ml_alerts[LABEL_COL].sum()
    
    heuristic_precision = (heuristic_tp / len(heuristic_alerts) * 100) if len(heuristic_alerts) > 0 else 0
    ml_precision = (ml_tp / len(ml_alerts) * 100) if len(ml_alerts) > 0 else 0
    
    st.markdown("#### Precisi√≥n de Detecci√≥n")
    precision_df = pd.DataFrame({
        'M√©todo': ['Heur√≠stico (Alto Riesgo)', 'ML (Umbral 1.5%)'],
        'Alertas Generadas': [len(heuristic_alerts), len(ml_alerts)],
        'Verdaderos Positivos': [heuristic_tp, ml_tp],
        'Precisi√≥n (%)': [f"{heuristic_precision:.2f}", f"{ml_precision:.2f}"]
    })
    st.dataframe(precision_df, use_container_width=True)
    
    # Visualizaci√≥n comparativa de scores
    st.markdown("#### Distribuci√≥n de Scores")
    st.caption("Comparaci√≥n visual entre Risk Score (heur√≠stico) y ML Model Score")
    
    comparison_df = df[['Risk Score', 'ML Model Score', LABEL_COL]].copy()
    comparison_df['M√©todo'] = comparison_df[LABEL_COL].map({0: 'Normal', 1: 'Amenaza'})
    
    fig_comparison = go.Figure()
    
    # Scatter plot comparando ambos scores
    fig_comparison.add_trace(go.Scatter(
        x=comparison_df['Risk Score'],
        y=comparison_df['ML Model Score'],
        mode='markers',
        marker=dict(
            color=comparison_df[LABEL_COL],
            colorscale='RdYlGn',
            showscale=True,
            colorbar=dict(title="Amenaza Real")
        ),
        text=comparison_df['M√©todo'],
        hovertemplate='Risk Score: %{x:.3f}<br>ML Score: %{y:.4f}<br>%{text}<extra></extra>'
    ))
    
    fig_comparison.update_layout(
        title="Comparaci√≥n de Scores: Heur√≠stico vs ML",
        xaxis_title="Risk Score (Heur√≠stico)",
        yaxis_title="ML Model Score",
        height=500
    )
    st.plotly_chart(fig_comparison, use_container_width=True)
    
    # Interpretaci√≥n del gr√°fico de comparaci√≥n de scores
    correlation = comparison_df['Risk Score'].corr(comparison_df['ML Model Score'])
    high_risk_high_ml = len(comparison_df[(comparison_df['Risk Score'] > 0.66) & (comparison_df['ML Model Score'] > 0.015)])
    high_risk_low_ml = len(comparison_df[(comparison_df['Risk Score'] > 0.66) & (comparison_df['ML Model Score'] <= 0.015)])
    low_risk_high_ml = len(comparison_df[(comparison_df['Risk Score'] <= 0.66) & (comparison_df['ML Model Score'] > 0.015)])
    
    st.caption(f"""
    **üìä Interpretaci√≥n**: Este gr√°fico compara los scores heur√≠sticos (eje X) con los scores del modelo ML (eje Y). 
    La correlaci√≥n entre ambos m√©todos es {correlation:.3f}, lo que indica {'una relaci√≥n fuerte' if abs(correlation) > 0.5 else 'una relaci√≥n moderada' if abs(correlation) > 0.3 else 'poca relaci√≥n'}.
    Los puntos rojos/amarillos representan amenazas reales. Si los puntos est√°n concentrados en la esquina superior derecha 
    (alto Risk Score y alto ML Score), ambos m√©todos est√°n de acuerdo. Si hay puntos en la esquina superior izquierda 
    ({low_risk_high_ml:,} casos: bajo Risk Score pero alto ML Score), el ML detecta amenazas que la heur√≠stica no. 
    Si hay puntos en la esquina inferior derecha ({high_risk_low_ml:,} casos: alto Risk Score pero bajo ML Score), 
    la heur√≠stica genera alertas que el ML considera normales. Ambos m√©todos son complementarios y juntos mejoran la detecci√≥n.
    """)
    
    # Tabla de casos interesantes
    st.markdown("#### Casos de Inter√©s")
    st.caption("Flujos donde los m√©todos difieren significativamente")
    
    # Casos donde ML detecta pero heur√≠stica no (y son amenazas reales)
    ml_correct_heuristic_missed = ml_only[ml_only[LABEL_COL] == 1]
    
    if not ml_correct_heuristic_missed.empty:
        st.markdown("**‚úÖ ML detect√≥ correctamente amenazas que la heur√≠stica pas√≥ por alto:**")
        st.dataframe(
            ml_correct_heuristic_missed[['ML Model Score', 'Risk Score', 'Risk Level', 
                                         'Flow Duration', 'Total Fwd Packets', LABEL_COL]].head(10),
            use_container_width=True
        )
    
    # Casos donde heur√≠stica detecta pero ML no (y son amenazas reales)
    heuristic_correct_ml_missed = heuristic_only[heuristic_only[LABEL_COL] == 1]
    
    if not heuristic_correct_ml_missed.empty:
        st.markdown("**‚úÖ Heur√≠stica detect√≥ correctamente amenazas que ML pas√≥ por alto:**")
        st.dataframe(
            heuristic_correct_ml_missed[['Risk Score', 'Risk Level', 'ML Model Score',
                                        'Flow Duration', 'Total Fwd Packets', LABEL_COL]].head(10),
            use_container_width=True
        )
    
    # Resumen de conclusiones
    st.markdown("#### Conclusiones de la Comparativa")
    
    conclusions = f"""
    **Hallazgos Clave:**
    
    1. **Cobertura Complementaria:** {'Ambos m√©todos detectan amenazas que el otro pasa por alto, lo que sugiere que son complementarios.' if (not ml_correct_heuristic_missed.empty and not heuristic_correct_ml_missed.empty) else 'Los m√©todos muestran diferentes patrones de detecci√≥n.'}
    
    2. **Precisi√≥n:** 
       - Heur√≠stico: {heuristic_precision:.2f}% de precisi√≥n ({heuristic_tp}/{len(heuristic_alerts)} alertas son reales)
       - ML: {ml_precision:.2f}% de precisi√≥n ({ml_tp}/{len(ml_alerts)} alertas son reales)
    
    3. **Volumen de Alertas:**
       - El m√©todo heur√≠stico genera {'m√°s' if len(heuristic_alerts) > len(ml_alerts) else 'menos'} alertas que el modelo ML
       - Esto impacta directamente en la carga de trabajo del analista
    
    4. **Recomendaci√≥n:** 
       - Considera usar ambos m√©todos en conjunto para maximizar la detecci√≥n
       - El modelo ML puede servir como filtro inicial m√°s preciso
       - La heur√≠stica puede capturar patrones espec√≠ficos que el ML no detecta
    """
    
    st.markdown(conclusions)


@st.cache_data(show_spinner="Entrenando y evaluando modelos...")
def train_and_evaluate_model(df: pd.DataFrame, dataset_name: str) -> dict:
    """
    Entrena un modelo de Regresi√≥n Log√≠stica y eval√∫a sus m√©tricas.
    """
    features = [
        "Flow Duration", "Total Fwd Packets", "Total Length of Fwd Packets",
        "Flow Bytes/s", "Flow IAT Mean", "Fwd Packet Length Mean", 
        "Bwd Packet Length Mean"
    ]
    target = LABEL_COL
    
    X = df[features]
    y = df[target]
    
    # Separar train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # Escalar
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Entrenar modelo
    model = LogisticRegression(max_iter=1000, random_state=42)
    model.fit(X_train_scaled, y_train)
    
    # Predicciones
    y_pred = model.predict(X_test_scaled)
    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
    
    # Calcular m√©tricas
    cm = confusion_matrix(y_test, y_pred)
    tn, fp, fn, tp = cm.ravel()
    
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_pred_proba)
    
    # ROC curve
    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
    
    return {
        "dataset_name": dataset_name,
        "cm": cm,
        "tn": tn, "fp": fp, "fn": fn, "tp": tp,
        "precision": precision,
        "recall": recall,
        "f1": f1,
        "auc": auc,
        "fpr": fpr,
        "tpr": tpr,
        "y_test": y_test,
        "y_pred": y_pred,
        "y_pred_proba": y_pred_proba,
        "classification_report": classification_report(y_test, y_pred, output_dict=True)
    }


def render_metrics_comparison(original_df: pd.DataFrame, balanced_df: pd.DataFrame) -> None:
    """
    Compara m√©tricas del modelo entrenado en dataset original vs balanceado.
    """
    st.subheader("Comparaci√≥n de M√©tricas: Dataset Original vs Balanceado")
    st.caption(
        "Comparaci√≥n completa de m√©tricas de evaluaci√≥n entre modelos entrenados "
        "en el dataset original y el dataset balanceado con SMOTE."
    )
    
    # Entrenar y evaluar ambos modelos
    with st.spinner("Entrenando modelos y calculando m√©tricas..."):
        results_original = train_and_evaluate_model(original_df, "Original")
        results_balanced = train_and_evaluate_model(balanced_df, "Balanceado")
    
    # Resumen ejecutivo
    st.markdown("### Resumen Ejecutivo")
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**Dataset Original**")
        st.metric("Recall (Detecci√≥n)", f"{results_original['recall']:.3f}")
        st.metric("Precision", f"{results_original['precision']:.3f}")
        st.metric("F1-Score", f"{results_original['f1']:.3f}")
        st.metric("ROC-AUC", f"{results_original['auc']:.3f}")
        st.metric("TP (Ataques detectados)", f"{results_original['tp']}")
        st.metric("FN (Ataques omitidos)", f"{results_original['fn']}")
    
    with col2:
        st.markdown("**Dataset Balanceado**")
        st.metric("Recall (Detecci√≥n)", f"{results_balanced['recall']:.3f}")
        st.metric("Precision", f"{results_balanced['precision']:.3f}")
        st.metric("F1-Score", f"{results_balanced['f1']:.3f}")
        st.metric("ROC-AUC", f"{results_balanced['auc']:.3f}")
        st.metric("TP (Ataques detectados)", f"{results_balanced['tp']}")
        st.metric("FN (Ataques omitidos)", f"{results_balanced['fn']}")
    
    # Comparaci√≥n visual de m√©tricas
    st.markdown("### Comparaci√≥n Visual de M√©tricas")
    
    metrics_df = pd.DataFrame({
        "M√©trica": ["Recall", "Precision", "F1-Score", "ROC-AUC"],
        "Original": [
            results_original['recall'],
            results_original['precision'],
            results_original['f1'],
            results_original['auc']
        ],
        "Balanceado": [
            results_balanced['recall'],
            results_balanced['precision'],
            results_balanced['f1'],
            results_balanced['auc']
        ]
    })
    
    fig_metrics = go.Figure()
    fig_metrics.add_trace(go.Bar(
        name="Original",
        x=metrics_df["M√©trica"],
        y=metrics_df["Original"],
        marker_color='#1f77b4'
    ))
    fig_metrics.add_trace(go.Bar(
        name="Balanceado",
        x=metrics_df["M√©trica"],
        y=metrics_df["Balanceado"],
        marker_color='#ff7f0e'
    ))
    fig_metrics.update_layout(
        title="Comparaci√≥n de M√©tricas",
        yaxis_title="Valor",
        barmode='group',
        height=400
    )
    st.plotly_chart(fig_metrics, use_container_width=True)
    
    # Matrices de confusi√≥n comparativas
    st.markdown("### Matrices de Confusi√≥n")
    col_cm1, col_cm2 = st.columns(2)
    
    with col_cm1:
        st.markdown("**Dataset Original**")
        cm_orig_df = pd.DataFrame(
            results_original['cm'],
            index=["Normal", "Amenaza"],
            columns=["Normal", "Amenaza"]
        )
        fig_cm_orig = px.imshow(
            cm_orig_df,
            text_auto=True,
            aspect="auto",
            color_continuous_scale='Blues',
            labels=dict(x="Predicho", y="Real", color="Cantidad"),
            title="Matriz de Confusi√≥n - Original"
        )
        st.plotly_chart(fig_cm_orig, use_container_width=True)
    
    with col_cm2:
        st.markdown("**Dataset Balanceado**")
        cm_bal_df = pd.DataFrame(
            results_balanced['cm'],
            index=["Normal", "Amenaza"],
            columns=["Normal", "Amenaza"]
        )
        fig_cm_bal = px.imshow(
            cm_bal_df,
            text_auto=True,
            aspect="auto",
            color_continuous_scale='Oranges',
            labels=dict(x="Predicho", y="Real", color="Cantidad"),
            title="Matriz de Confusi√≥n - Balanceado"
        )
        st.plotly_chart(fig_cm_bal, use_container_width=True)
    
    # Curvas ROC comparativas
    st.markdown("### Curvas ROC")
    fig_roc = go.Figure()
    
    fig_roc.add_trace(go.Scatter(
        x=results_original['fpr'],
        y=results_original['tpr'],
        mode='lines',
        name=f"Original (AUC={results_original['auc']:.3f})",
        line=dict(color='blue', width=2)
    ))
    
    fig_roc.add_trace(go.Scatter(
        x=results_balanced['fpr'],
        y=results_balanced['tpr'],
        mode='lines',
        name=f"Balanceado (AUC={results_balanced['auc']:.3f})",
        line=dict(color='orange', width=2)
    ))
    
    # L√≠nea diagonal (clasificador aleatorio)
    fig_roc.add_trace(go.Scatter(
        x=[0, 1],
        y=[0, 1],
        mode='lines',
        name='Clasificador aleatorio',
        line=dict(color='red', dash='dash', width=1)
    ))
    
    fig_roc.update_layout(
        title="Curvas ROC Comparativas",
        xaxis_title="Tasa de Falsos Positivos (FPR)",
        yaxis_title="Tasa de Verdaderos Positivos (TPR)",
        height=500
    )
    st.plotly_chart(fig_roc, use_container_width=True)
    
    # An√°lisis de detecci√≥n de ataques
    st.markdown("### An√°lisis de Detecci√≥n de Ataques")
    
    analysis_cols = st.columns(2)
    
    with analysis_cols[0]:
        st.markdown("**Dataset Original**")
        recall_orig = results_original['recall']
        if recall_orig >= 0.9:
            st.success(f"‚úÖ **Recall alto ({recall_orig:.3f})**: El modelo detecta correctamente la mayor√≠a de ataques.")
        elif recall_orig >= 0.7:
            st.warning(f"‚ö†Ô∏è **Recall moderado ({recall_orig:.3f})**: El modelo detecta muchos ataques pero omite algunos.")
        else:
            st.error(f"‚ùå **Recall bajo ({recall_orig:.3f})**: El modelo omite muchos ataques. Necesita ajuste.")
        
        precision_orig = results_original['precision']
        if precision_orig >= 0.7:
            st.success(f"‚úÖ **Precision alta ({precision_orig:.3f})**: Pocas falsas alarmas.")
        else:
            st.warning(f"‚ö†Ô∏è **Precision baja ({precision_orig:.3f})**: Muchas falsas alarmas.")
    
    with analysis_cols[1]:
        st.markdown("**Dataset Balanceado**")
        recall_bal = results_balanced['recall']
        if recall_bal >= 0.9:
            st.success(f"‚úÖ **Recall alto ({recall_bal:.3f})**: El modelo detecta correctamente la mayor√≠a de ataques.")
        elif recall_bal >= 0.7:
            st.warning(f"‚ö†Ô∏è **Recall moderado ({recall_bal:.3f})**: El modelo detecta muchos ataques pero omite algunos.")
        else:
            st.error(f"‚ùå **Recall bajo ({recall_bal:.3f})**: El modelo omite muchos ataques. Necesita ajuste.")
        
        precision_bal = results_balanced['precision']
        if precision_bal >= 0.7:
            st.success(f"‚úÖ **Precision alta ({precision_bal:.3f})**: Pocas falsas alarmas.")
        else:
            st.warning(f"‚ö†Ô∏è **Precision baja ({precision_bal:.3f})**: Muchas falsas alarmas.")
    
    # Tabla comparativa detallada
    st.markdown("### Tabla Comparativa Detallada")
    comparison_table = pd.DataFrame({
        "M√©trica": [
            "Recall (Detecci√≥n de ataques)",
            "Precision",
            "F1-Score",
            "ROC-AUC",
            "Verdaderos Positivos (TP)",
            "Falsos Negativos (FN)",
            "Falsos Positivos (FP)",
            "Verdaderos Negativos (TN)"
        ],
        "Original": [
            f"{results_original['recall']:.4f}",
            f"{results_original['precision']:.4f}",
            f"{results_original['f1']:.4f}",
            f"{results_original['auc']:.4f}",
            f"{results_original['tp']}",
            f"{results_original['fn']}",
            f"{results_original['fp']}",
            f"{results_original['tn']}"
        ],
        "Balanceado": [
            f"{results_balanced['recall']:.4f}",
            f"{results_balanced['precision']:.4f}",
            f"{results_balanced['f1']:.4f}",
            f"{results_balanced['auc']:.4f}",
            f"{results_balanced['tp']}",
            f"{results_balanced['fn']}",
            f"{results_balanced['fp']}",
            f"{results_balanced['tn']}"
        ],
        "Diferencia": [
            f"{results_balanced['recall'] - results_original['recall']:+.4f}",
            f"{results_balanced['precision'] - results_original['precision']:+.4f}",
            f"{results_balanced['f1'] - results_original['f1']:+.4f}",
            f"{results_balanced['auc'] - results_original['auc']:+.4f}",
            f"{results_balanced['tp'] - results_original['tp']:+d}",
            f"{results_balanced['fn'] - results_original['fn']:+d}",
            f"{results_balanced['fp'] - results_original['fp']:+d}",
            f"{results_balanced['tn'] - results_original['tn']:+d}"
        ]
    })
    st.dataframe(comparison_table, use_container_width=True)
    
    # Conclusiones
    st.markdown("### Conclusiones")
    
    if results_balanced['recall'] > results_original['recall']:
        st.success(
            f"‚úÖ **El dataset balanceado mejora el Recall**: "
            f"{results_balanced['recall']:.3f} vs {results_original['recall']:.3f}. "
            "El balanceo ayuda a detectar mejor los ataques minoritarios."
        )
    else:
        st.info(
            f"‚ÑπÔ∏è **El dataset original tiene mejor Recall**: "
            f"{results_original['recall']:.3f} vs {results_balanced['recall']:.3f}."
        )
    
    if results_balanced['fn'] < results_original['fn']:
        st.success(
            f"‚úÖ **Menos ataques omitidos con balanceo**: "
            f"{results_balanced['fn']} vs {results_original['fn']} falsos negativos."
        )
    
    if results_balanced['precision'] < results_original['precision']:
        st.warning(
            f"‚ö†Ô∏è **El balanceo puede aumentar falsas alarmas**: "
            f"Precision {results_balanced['precision']:.3f} vs {results_original['precision']:.3f}."
        )
    
    st.markdown("""
    **Resumen del proceso:**
    1. ‚úÖ Separaci√≥n train/test (80/20) con estratificaci√≥n
    2. ‚úÖ Entrenamiento de modelos en ambos datasets
    3. ‚úÖ Evaluaci√≥n con m√©tricas clave (Recall, Precision, F1, ROC-AUC)
    4. ‚úÖ Comparaci√≥n visual de resultados
    5. ‚úÖ An√°lisis de detecci√≥n de ataques minoritarios
    
    **Pr√≥ximos pasos recomendados:**
    - Si el Recall en la clase maliciosa es bajo, ajustar hiperpar√°metros
    - Validar con datos reales
    - Implementar monitoreo continuo
    """)


def main() -> None:
    st.set_page_config(
        page_title="An√°lisis de Ciberseguridad",
        page_icon="üõ°Ô∏è",
        layout="wide",
    )
    st.title("Datamart de Ciberseguridad")
    st.markdown(
        """
        Esta aplicaci√≥n permite explorar las m√©tricas del datamart de ciberseguridad y
        comparar el comportamiento entre tr√°fico normal y amenazas (escaneos de puertos).
        """
    )

    uploaded_file = st.sidebar.file_uploader(
        "Sube un CSV alternativo",
        type=["csv"],
        help="Si no subes nada, se usar√° el dataset por defecto del repositorio.",
    )
    try:
        raw_df = load_data(uploaded_file)
    except FileNotFoundError as exc:
        st.error(str(exc))
        st.stop()

    if LABEL_COL not in raw_df.columns:
        st.error(f"El dataset debe contener la columna '{LABEL_COL}'.")
        st.stop()

    dataset_option = st.sidebar.selectbox(
        "Modo de an√°lisis",
        (
            "Dataset original",
            "Dataset balanceado (SMOTE)",
        ),
        help="El balanceo SMOTE genera ejemplos sint√©ticos de la clase minoritaria "
        "para equilibrar el conjunto. √ösalo para evaluar modelos sin sesgo por "
        "frecuencia, pero recuerda que los registros adicionales son sint√©ticos.",
    )

    base_enriched = enrich_with_cyber_features(raw_df)

    # Entrenar modelo de ML y obtener sus predicciones
    model_results_df = None
    auc_score = None
    try:
        model_results_df, auc_score = train_and_get_model_predictions(raw_df)
        # Fusionar los resultados del ML con los datos enriquecidos (heur√≠sticos)
        # Asegurarse de que los √≠ndices coincidan
        base_enriched = base_enriched.join(model_results_df, how='left')
    except Exception as e:
        st.warning(f"No se pudo entrenar el modelo de ML: {str(e)}")
        model_results_df = None
        auc_score = None

    if dataset_option.startswith("Dataset balanceado"):
        if "balanced_df_raw" not in st.session_state:
            with st.spinner("Generando dataset balanceado con SMOTE..."):
                st.session_state["balanced_df_raw"] = balance_data(raw_df)
        df_view = enrich_with_cyber_features(st.session_state["balanced_df_raw"])
        # Nota: El modelo de ML solo se entrena y aplica al dataset original.
        # Para el dataset balanceado, no fusionamos las columnas ML ya que los √≠ndices no coinciden
        dataset_label = "balanceado con SMOTE"
    else:
        df_view = base_enriched
        dataset_label = "original"

    tabs = st.tabs(
        [
            "Visi√≥n general",
            "Distribuci√≥n y estad√≠sticas",
            "An√°lisis interactivo",
            "Ciberseguridad (Heur√≠stico)",
            "Modelo ML (Predictivo)",
            "Calibraci√≥n de Umbral (Fase 5)",
            "Comparativa (Heur√≠stico vs. ML)",
            "Balanceo",
            "Comparaci√≥n de M√©tricas",
        ]
    )

    with tabs[0]:
        render_overview(df_view, dataset_label)
        st.divider()
        render_class_distribution(df_view)

    with tabs[1]:
        render_statistics(df_view)
        st.divider()
        render_correlations(df_view)

    with tabs[2]:
        render_flow_analysis(df_view)

    with tabs[3]:
        render_cybersecurity_focus(df_view)
    
    with tabs[4]:
        if model_results_df is not None and 'ML Model Score' in df_view.columns and auc_score is not None:
            render_model_results(df_view, auc_score)
        else:
            st.info(
                "Los resultados del modelo de ML est√°n disponibles solo cuando se selecciona "
                "'Dataset original' en la barra lateral."
            )
    
    with tabs[5]:
        # Pesta√±a de Calibraci√≥n de Umbral
        try:
            if model_results_df is not None and 'ML Model Score' in df_view.columns:
                render_calibration_tuning(df_view)
            else:
                st.info(
                    "‚ö†Ô∏è **El visualizador de calibraci√≥n est√° disponible solo cuando se selecciona "
                    "'Dataset original' en la barra lateral.**\n\n"
                    "Por favor, cambia a 'Dataset original' en el selector de la barra lateral para ver "
                    "c√≥mo el umbral de decisi√≥n afecta el rendimiento del modelo."
                )
                st.markdown("---")
                st.markdown("#### ¬øQu√© es la Calibraci√≥n de Umbral?")
                st.caption(
                    "La calibraci√≥n de umbral es un proceso cr√≠tico en la Fase 5 de CRISP-DM que permite "
                    "ajustar el punto de corte de decisi√≥n del modelo para optimizar el balance entre "
                    "detecci√≥n de amenazas (TP) y falsas alarmas (FP)."
                )
        except Exception as e:
            st.error(f"Error al mostrar el visualizador de calibraci√≥n: {str(e)}")
            st.info("Aseg√∫rate de estar usando el 'Dataset original' en la barra lateral.")
    
    with tabs[6]:
        if model_results_df is not None and 'ML Model Score' in df_view.columns:
            render_comparison(df_view)
        else:
            st.info(
                "La comparativa est√° disponible solo cuando se selecciona "
                "'Dataset original' en la barra lateral."
            )

    with tabs[7]:
        if dataset_option.startswith("Dataset balanceado"):
            render_balance_section(base_enriched, df_view)
        else:
            st.info(
                "Selecciona 'Dataset balanceado (SMOTE)' en la barra lateral para comparar ambos conjuntos."
            )
    
    with tabs[8]:
        # Asegurar que el dataset balanceado est√© disponible
        if "balanced_df_raw" not in st.session_state:
            with st.spinner("Generando dataset balanceado con SMOTE..."):
                st.session_state["balanced_df_raw"] = balance_data(raw_df)
        
        render_metrics_comparison(raw_df, st.session_state["balanced_df_raw"])

    st.sidebar.markdown("### Informaci√≥n del dataset")
    st.sidebar.write(f"Filas (vista actual): {len(df_view):,}")
    st.sidebar.write(f"Columnas: {len(df_view.columns)}")
    st.sidebar.write(
        "Columnas disponibles:",
        df_view.columns.tolist(),
    )


if __name__ == "__main__":
    main()

